{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15765ad1-cb74-4a89-9d86-fb900e99a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6eb44-3f12-402e-8175-ad3fe22c2a52",
   "metadata": {},
   "source": [
    "# 2. From Text to Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d249e12-3c99-475e-b866-689ba2235597",
   "metadata": {},
   "source": [
    "### 2.1 Subword Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b2926-9a45-443d-839d-2bb23ff4af5e",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b00ae09-3e93-4afc-bc89-abf29b101194",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"gpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a56416-f9fd-410a-a6b9-df4709d23f6e",
   "metadata": {},
   "source": [
    "Load the `gpt2` tokenizer and tokenize the text `persistence is all you need`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9588b37-0340-4060-ab5b-8e62f7d6c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80159dc5-ad42-4116-8b3a-45db9fcdaa0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd058f9cd600465c84a096df32c5ee04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e88ab5348dc4fb0b557f650911bcf20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7997fe4a6a75428ba8120878d5e009b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe742a4b75944808bb9292be9cafb185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b50ca8d-17b0-4c2b-9b85-1b606f0f361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(\"Persistence is all you need.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68b3071f-7b7e-47f9-946b-a4c971aebfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [30946, 13274, 318, 477, 345, 761, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55779c-b05e-44ac-8745-ddfd8fe2882d",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5782ea8f-4dc2-48bd-803b-51da63906158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5550c517cf5434790777fc5574b83b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483d6887af9e4bb6b4fc5566841eb31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543b5f8ae9da4f8e89a133a3f7aa925e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b089def9bd73455581716818647a5e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2060f54-9c99-4166-9cd4-c07fdf07b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Persistence is all you need. Tokenizing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f331b4f9-233b-40f2-a88e-38a7d3c9353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer(\"Persistence is all you need. Tokenizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4290cd16-d5d3-413a-9d7b-fc1b256d856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e007574b-3ea3-4a37-b6d4-7678c682cf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Persistence is all you need. Tokenizing'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab41e0b-778a-44b8-a4ce-050d6846e75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffd1ec9b-b745-4efd-b7b4-3858b482eda3",
   "metadata": {},
   "source": [
    "`tokens` is a list of tokens of the `text` from `distilbert-base-uncased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e1856c1-cf92-4346-8dc5-0195a65ecf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'persistence',\n",
       " 'is',\n",
       " 'all',\n",
       " 'you',\n",
       " 'need',\n",
       " '.',\n",
       " 'token',\n",
       " '##izing',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef634bb-c99e-415b-83f6-1358a458997f",
   "metadata": {},
   "source": [
    "**Question 1**: What is `[CLS]` and `[SEP]`?\n",
    "\n",
    "These're tokens that indicate the start and the end of the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e051b9e-173e-4750-aa92-9039d7e83a16",
   "metadata": {},
   "source": [
    "**Question 2**: What does the prefix `##` in `##izing` mean?\n",
    "\n",
    "It's means that that the preceding string is not whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf5377-f59b-4991-9bf2-7b4220021166",
   "metadata": {},
   "source": [
    "**Question 3**: How does the tokenizer differentiate between tokens with and without the `##` prefix when converting tokens to text?\n",
    "\n",
    "- Tokens with the `##` prefix are subwords that have been combined to form a single token during the tokenization process. When the Tokenizer converts these tokens back to text, it removes the `##` prefix and combines the subwords into a single word.\n",
    "\n",
    "- Tokens without the `##` prefix are treated as regular words that are present in the model's vocabulary, and they are not modified during the conversion process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ccd052-3ed9-4220-811c-a901f556b6d9",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599e162f-a0a1-41f1-85e2-cb98f92b7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5af3ba9-d7de-44d2-b936-0111ecad2eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration DDSC--angry-tweets-37d8dddb9469d99e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/DDSC--angry-tweets to /root/.cache/huggingface/datasets/DDSC___parquet/DDSC--angry-tweets-37d8dddb9469d99e/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713dba9aa2264f60bcfe8fda49a13429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62216609ecb44dc598311bc81426f226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/120k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4c178d4851486eab4b61ecb1eff0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/269k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c427c369d4408fb4abcc67ea053d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/DDSC___parquet/DDSC--angry-tweets-37d8dddb9469d99e/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd584c7525f04cb49a51b6b18758374a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"DDSC/angry-tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05446e39-889c-46bf-bc20-9cac717c9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset['train'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11f0298b-b08c-4da6-b829-b3be32e31b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Et stort tillykke til @USER og vinderne af Ã¥rets Cavlingpris ðŸ’ªðŸ¼ [LINK]',\n",
       "  '@USER Jeg lukkede den faktisk ned inden et mÃ¸de ðŸ˜¬',\n",
       "  '@USER AsÃ­ es, para jugar un partido se requieren dos equipos.'],\n",
       " 'label': ['positiv', 'neutral', 'neutral']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b901f4a0-be69-4e70-b6ab-d268476d4630",
   "metadata": {},
   "source": [
    "Write a function `tokenize` a batch of text as bellow given `tokenizer` is a transformer's tokenizer. Explain each parameters in the function\n",
    "\n",
    "**Hint**: There's one parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44cd9ec8-316d-4b9c-b185-b712acd82151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3077719-e1e9-4e64-9623-c7b4f61f8e77",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "\n",
    "Because the tokenized text all have the same length => set `padding=True` to add special padding tokens to the end of shorter sequences until they reach the maximum input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73d41b72-d976-47a6-b395-3055b1aa93ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenize(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ef06400-31fa-4fca-a5fd-2a37c9fa9e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 27, 27]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, encoded_text.input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e73016b3-a01d-401e-b864-b5de99fe4e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3802, 2358, 11589, 6229, 15922, 3489, 18681, 1030, 5310, 13958, 19354, 25888, 2063, 21358, 2024, 3215, 6187, 2615, 2989, 18098, 2483, 100, 1031, 4957, 1033, 102], [101, 1030, 5310, 15333, 2290, 11320, 19658, 14728, 7939, 6904, 22462, 6711, 12311, 27427, 2368, 3802, 1049, 16415, 3207, 100, 102, 0, 0, 0, 0, 0, 0], [101, 1030, 5310, 2004, 2072, 9686, 1010, 11498, 26536, 2906, 4895, 2112, 13820, 7367, 2128, 15549, 7869, 2078, 9998, 1041, 15549, 6873, 2015, 1012, 102, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36027a-c682-421a-a5cc-7825da22706d",
   "metadata": {},
   "source": [
    "##### Example 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ebe9350-5c0e-421a-91d0-ec1be82ebe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72cfa624-ba78-426a-bee4-07ac0ccb1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d8f3c9f-f8be-4aea-8095-f8babfcbde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(\"Persistence is all you need.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5265433-2ee5-46ba-b7b3-b3488c6e19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = output.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c606cc6d-5e61-4aac-a448-8e2e7bdecf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f2b446-d063-41a4-a140-1ce827bd36d1",
   "metadata": {},
   "source": [
    "Convert a list of `input_ids` representing a sequence back into the original text given `tokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa9cb948-1020-402f-8be9-ac09a999db1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30946, 13274, 318, 477, 345, 761, 13]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "468904b9-2148-406c-9b64-0f45d5d988f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f94cf852-9a36-4620-8542-f1773dc09a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pers', 'istence', 'Ä is', 'Ä all', 'Ä you', 'Ä need', '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abd2b72b-80b5-4720-b2dc-251f9c826d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.convert_tokens_to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe6cdaa4-5eb5-4312-9d07-a588f0f654bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Persistence is all you need.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e3736b-e15e-46b5-a446-37aebfdc788c",
   "metadata": {},
   "source": [
    "##### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "576bea69-4d63-4678-a81f-5f48640643cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a932ecb1e04667bddb54bb1a243a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4ab821b62a45e6afbd21bb3cf494a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "35c675bf-8d70-4615-b078-8191a7ffb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_encoded['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832f63c-a09f-4fe6-9471-0e190e62c787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c94f2e9c-46a9-41a8-8e49-649bcb12baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aea7dc13-318d-4921-b529-ab69b9caa573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e55b7f71944c4e94d20609666e2d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0f879af2-7738-40ec-8b75-32dabed1c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"this is a test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5f55bdf4-ffe2-412b-8d85-fd66d7ddafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6c89c8ce-0607-4c8e-bc64-395274cfdd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3231,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0d02f833-9614-41ab-90fb-ebeb0beba08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {k:v.to(device) for k,v in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "17c25da1-997e-4825-b43d-e5ee33fb4fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3231,  102]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "697bafba-6538-494d-9815-a079aa8227af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7988102e-ae60-420d-b321-db8f29ce344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.1565, -0.1862,  0.0528,  ..., -0.1188,  0.0662,  0.5470],\n",
       "         [-0.3575, -0.6484, -0.0618,  ..., -0.3040,  0.3508,  0.5221],\n",
       "         [-0.2772, -0.4459,  0.1818,  ..., -0.0948, -0.0076,  0.9958],\n",
       "         [-0.2841, -0.3917,  0.3753,  ..., -0.2151, -0.1173,  1.0526],\n",
       "         [ 0.2661, -0.5094, -0.3180,  ..., -0.4203,  0.0144, -0.2149],\n",
       "         [ 0.9441,  0.0112, -0.4714,  ...,  0.1439, -0.7288, -0.1619]]],\n",
       "       device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "64dbda17-9e39-48f8-9dc0-4ea376064e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "27fdb126-dde5-4d99-9956-f1338b3f6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [[1, 2, 3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece23814-1f67-4402-8a73-cc750764b541",
   "metadata": {},
   "source": [
    "# 3. Training a Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f68264-1ae8-406a-841d-cbbdf49fa0f1",
   "metadata": {},
   "source": [
    "### 3.2 Fine-Tuning Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d23cc-6d8d-4f39-b02c-bee433f5929b",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0a3da1dc-06b4-416b-be8d-7800cc67d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fdb34755-df7e-461d-b1c9-9204b726f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e3f70513-fb44-42fd-824a-fdd5face0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5284a71b-3f43-40c8-b431-27c3fa56950f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt, num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a5dfaf19-553f-4d18-b655-5f829fad28e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf5184805ab46fda3e6da91fd767a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3aff7cb6be64a31be6e83ea517f9ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f11c6090-0d59-44a9-b195-0947436f1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bccffe1a-77aa-4af1-a5f9-ca9b61e3c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "logging_steps = len(dataset_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=True, \n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b0b594da-d796-40c8-8d49-94651dfb55f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=IntervalStrategy.EPOCH,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_min_num_params=0,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=40,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=distilbert-base-uncased-finetuned-emotion/runs/Dec31_03-33-24_ny1s2vbueq,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=37,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=2,\n",
       "optim=OptimizerNames.ADAMW_HF,\n",
       "output_dir=distilbert-base-uncased-finetuned-emotion,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=64,\n",
       "per_device_train_batch_size=64,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=True,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=distilbert-base-uncased-finetuned-emotion,\n",
       "save_on_each_node=False,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.STEPS,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "03eb1a90-4f2e-43a4-9528-1ea5748243b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "911e9b57-4b73-4db1-bbb7-e92dac133f83",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [177]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel, args\u001b[38;5;241m=\u001b[39mtraining_args, \n\u001b[1;32m      4\u001b[0m                   compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      5\u001b[0m                   train_dataset\u001b[38;5;241m=\u001b[39mdataset_encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m----> 6\u001b[0m                   eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mdataset_encoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      7\u001b[0m                   tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/dataset_dict.py:50\u001b[0m, in \u001b[0;36mDatasetDict.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, k) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, (\u001b[38;5;28mstr\u001b[39m, NamedSplit)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         available_suggested_splits \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     53\u001b[0m             \u001b[38;5;28mstr\u001b[39m(split) \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m (Split\u001b[38;5;241m.\u001b[39mTRAIN, Split\u001b[38;5;241m.\u001b[39mTEST, Split\u001b[38;5;241m.\u001b[39mVALIDATION) \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m     54\u001b[0m         ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'validation'"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=dataset_encoded[\"train\"],\n",
    "                  eval_dataset=dataset_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be861504-5106-4d16-80e2-ce414e0d1d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4c219-afcf-4d46-9de8-dd8e571e8563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
