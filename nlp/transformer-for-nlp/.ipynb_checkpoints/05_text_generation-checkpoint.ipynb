{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c96d9968-995c-4b77-bc14-41609fa15bca",
   "metadata": {},
   "source": [
    "# Chapter 5: Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14e16a-1e03-46fd-a8b5-2771551c9922",
   "metadata": {},
   "source": [
    "### 1. The Challenge with Generating Coherent Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f55529-07e3-42bb-b94b-57e69676a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e118b631-6fe4-4cbf-be83-f916ddd97bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c786f312-ad55-40ef-8e59-2d77f5d59574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a1cc25-a883-4c9a-817f-fee634c19acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-xl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e4f4aee-f034-40ac-8520-f9478b209504",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51f36a6-f7fe-4bdb-a161-edf196c42f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af2eee2-5e97-4964-92af-f7574d5532c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = \"persistence is all you need\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3cb24cd-01d6-44f7-8465-1ed139d9a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f73c4cc-6814-4af3-b08c-1916080ba38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c99ce3d-b394-422a-9ef5-d7b807657dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 8\n",
    "choices_per_step = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c71608-a4a7-4d08-8182-445ae7443709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19276, 13274,   318,   477,   345,   761]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76ce1959-f166-442d-b83d-46047cd40719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19276, 13274,   318,   477,   345,   761], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6e0154-bec3-4539-9610-0fc893ca5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids=input_ids)\n",
    "        \n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "            \n",
    "        # sorted_ids = torch.argsort(next_token_probs, dim=-1, desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb1bd834-cf22-4981-bf14-a05b5f35d29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'persistence is all you need'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "789a0071-8636-4926-867b-38012e741752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75e35d0e-63ab-4252-a7bb-ed5fe747d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94c27bf7-055f-4e0c-b77f-5a61a8c2f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c9503f6-bd93-4385-abcd-2ed5102e2c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8732,  3.6249,  0.2828,  ..., -6.4631, -2.5632,  1.3299],\n",
       "        [ 2.4064,  6.1909,  1.8162,  ..., -5.2652, -4.9478,  2.1214],\n",
       "        [ 0.5427,  1.6651, -2.6166,  ..., -7.3001, -4.4530, -0.3493],\n",
       "        [ 3.0592,  1.4659, -2.7849,  ..., -6.8109, -5.2147, -0.3743],\n",
       "        [ 3.4758,  2.9291, -0.9446,  ..., -5.3347, -2.7920,  0.8841],\n",
       "        [ 7.5406,  5.7096,  0.6126,  ..., -7.7698, -7.9736,  4.4805]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8311332e-10ec-4a88-98c8-187e6549b0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbe00102-a908-459e-b28a-76403c93eb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.5406,  5.7096,  0.6126,  ..., -7.7698, -7.9736,  4.4805],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits[0][-1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "490c22ba-ab99-47a7-ae65-c9ff3846fa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.5406,  5.7096,  0.6126,  ..., -7.7698, -7.9736,  4.4805],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8524b7f6-42b3-4931-987f-63b8c226c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = output.logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccb838ae-404b-4d9e-bcea-210325d24bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1147e-02, 3.3888e-03, 2.0722e-05,  ..., 4.7428e-09, 3.8681e-09,\n",
       "        9.9148e-04], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(next_token_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ac9dba4-4b8e-4bff-8741-2bd237308c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt2 = \"persistence is all you need tores the five most probable tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cf40a06-5ab6-463e-8a4e-aa6a84b577fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_txt2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5546552-506c-42de-81a0-715123170834",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids2 = tokenizer(input_txt2, return_tensors=\"pt\")[\"input_ids\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c35ebb92-4de6-40fd-894e-12c4550632f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "038709e7-8eb8-41d1-b27e-90caa18e4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = model(input_ids=input_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fb1abb2-368a-494b-8935-053ff398b5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output2.logits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a42cd-4117-43c8-84e3-ce4107a12eea",
   "metadata": {},
   "source": [
    "# Flashcards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00269993-4d90-49b6-aee5-6da036a91d36",
   "metadata": {},
   "source": [
    "### 2. Greedy Search Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb0d89-e3bb-41a1-a763-303b8f05a732",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bfd6222-c11b-4158-8a81-66abb2f5dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The world is going to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1602f3bc-a267-418a-b171-fe99fbe73e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "704f7118-ac06-402e-9981-631ba3d8da73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 464,  995,  318, 1016,  284]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3b097e-6500-4629-93a5-29b38e661327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da67b6-93b5-424a-af03-f5dc7159a88e",
   "metadata": {},
   "source": [
    "Given a tokenized text `input_ids`, generate a prediction for the next word in the sequence and convert the predicted tokens for the first word to their corresponding ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48152f57-94d9-4e93-afa9-a31258b3c7fa",
   "metadata": {},
   "source": [
    "**Hint**: `next_token_logits = output.logits[0, -1, :]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36793d66-69cd-46f4-a3a2-29c4ec2230ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea59c0bc-605b-43ed-a1a7-84e96c50f3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 50257])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17ccb1f5-0c8e-4b78-bc69-67f8ba77e0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2333, -0.1872, -3.2762,  ..., -2.9148, -5.0910, -1.0786],\n",
       "         [ 2.4011,  3.5135, -1.9742,  ..., -7.9800, -1.3352,  0.3985],\n",
       "         [ 0.3600,  0.7970, -3.2943,  ..., -5.8384, -3.4494, -0.4427],\n",
       "         [ 1.2610,  2.0624, -2.2482,  ..., -6.9114, -8.1211, -1.2510],\n",
       "         [ 0.2554,  0.5884, -2.6440,  ..., -6.0750, -7.4630, -0.4967]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e22a0-6a48-4917-a3be-d36f563e5556",
   "metadata": {},
   "source": [
    "Given `output` is the output of a pre-trained `gpt2-xl` model generated using `transformers`\n",
    "\n",
    "Extract the logit of the 5th vocabulary and explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d5ad060-170c-49a5-91f8-2a9ece362b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits[0, -1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4383445d-e6a2-4422-955d-374b14b2d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = output.logits[0, -1, :][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242a76d-4cb6-45dd-9c7b-a588222b9041",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "\n",
    "`output.logits[0, -1, :]`\n",
    "- Returns the logits for all tokens in the vocabulary for the last timestep of the sequence\n",
    "- This is because `output.logits` has a shape of `[batch_size, sequence_length, vocabulary_size]`, and `[0, -1, :]` indexes the logits for the first item in the batch and the last timestep of the sequence\n",
    "\n",
    "`output.logits[0, -1, :][4]`\n",
    "- Returns the logit for the 5th token in the vocabulary\n",
    "- This is because `output.logits[0, -1, :]` is a 1-dimensional tensor with a size equal to the `vocab_size`, and `[4]` indexes the 5th element in that tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16d38896-73b4-4c3d-a6df-782a08adcb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.4703, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ba15c-14f7-4aa7-a246-227345eda9bb",
   "metadata": {},
   "source": [
    "##### Example 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07823fe-bf0f-4dbb-ab61-ff9eb1d46ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The world is going to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f424d2ba-eead-4ee1-a6ff-5a1fc411ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ed98ad0-b24b-42c2-8e69-8787e28b7956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 464,  995,  318, 1016,  284]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34fddedc-b8aa-4e75-bcba-0a0ef3569eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4abf2a-fa12-4096-a001-276f4e239a24",
   "metadata": {},
   "source": [
    "Given a tokenized text `input_ids`, generate a prediction for the next word in the sequence and convert the predicted tokens for the first word to their corresponding ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8bad5-39b1-4070-a522-e16b6b078ec9",
   "metadata": {},
   "source": [
    "**Hint**: `next_token_logits = output.logits[0, -1, :]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a810ff99-303b-403e-b5e2-3c166b560de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5923c6c-8cfa-4fee-b4b9-83dc81a6e74a",
   "metadata": {},
   "source": [
    "Retrieve the `ids` of the 5th word with the highest probability from `output`, which is the output of a pre-trained `gpt2-xl` model using `transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf29017e-cab2-4412-81a6-1c85f24ad244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 50257])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b06e39f-c419-48ed-9a54-fb870a9dbc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2333, -0.1872, -3.2762,  ..., -2.9148, -5.0910, -1.0786],\n",
       "         [ 2.4011,  3.5135, -1.9742,  ..., -7.9800, -1.3352,  0.3985],\n",
       "         [ 0.3600,  0.7970, -3.2943,  ..., -5.8384, -3.4494, -0.4427],\n",
       "         [ 1.2610,  2.0624, -2.2482,  ..., -6.9114, -8.1211, -1.2510],\n",
       "         [ 0.2554,  0.5884, -2.6440,  ..., -6.0750, -7.4630, -0.4967]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1340fefa-4430-4042-bbf3-e04ad1243814",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = output.logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e2c63dd-2254-4993-9dd1-9aeb4ddc4ba1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'next_token_logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnext_token_logits\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'next_token_logits' is not defined"
     ]
    }
   ],
   "source": [
    "next_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3dda763-ddd9-4dd6-bb0e-adc59fe835b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next_token_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d47bf9e2-774b-4ff0-b4e5-60cef1d6d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_probs = torch.softmax(next_token_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8180bde1-b3b1-4df8-9df9-f6da69cea8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6565daa1-187b-4e29-8662-da10ea190858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5968,  307,  886, 1487,  423], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57853ec8-8865-497e-bf62-9fc2b3a28d7b",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2beafff3-0189-4832-8d25-43be0cab11e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 464,  995,  318, 1016,  284]], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4714de87-3027-478e-85be-2c7c83a00f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel,\n",
       " transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model), type(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1dcff8-944c-4def-8db6-fe6a95941d0c",
   "metadata": {},
   "source": [
    "Predict the next `10` words in the sequence given the tokenized text `input_ids` of sequence \"The world is going to\" using the `model`\n",
    "\n",
    "**Hint** Convert `output` to text using `tokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b6ab0e2-cae6-412a-bb8f-24869538d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78c63eae-c2f9-45dd-9167-987a905be167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_new_tokens=max_new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c47e8a9-a9ec-4f12-9bfa-27d5ac9ee484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  464,   995,   318,  1016,   284,  5968,   287,   257,  1021,    65,\n",
       "         11715,    13,   198,   198,   464,   995,   318,  1016,   284,  5968,\n",
       "           287,   257,  1021,    65, 11715]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abf509fc-89b3-434a-bcbf-de4c49b38c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ceccc5a-c152-4f29-a8e0-e77ec891d738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The world is going to hell in a handbasket.\\n\\nThe world is going to hell in a handbasket'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81b5c5-f28e-4ab4-9382-9f32c947f1cb",
   "metadata": {},
   "source": [
    "### 3. Beam Search Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1fdf3-b4b9-486f-b1c7-06aec4e649a7",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "394d3439-7a4a-4248-b8c9-ee0dd2f1fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4bf6f5ff-0898-444f-9d18-3bc34660315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.tensor([[0], [1], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e224c4c1-d632-4c20-8373-47e766692a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "894f8ba1-ff3b-4295-a9c2-5dfdd971f371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d5839-2eb0-4732-900e-b48bbc5a89b6",
   "metadata": {},
   "source": [
    "Write a line of code using `torch.gather` that selects elements from the second dimension of tensor `x` based on the values in tensor `indices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "373b2290-65b2-4771-b887-2e253429acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_elements = torch.gather(x, dim=1, index=indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343ef57-3c37-4dfd-bc25-7ae36dfc5194",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "\n",
    "- `torch.gather` is a function that allows you to select specific elements from a tensor along a given dimension\n",
    "\n",
    "- `dim=1`: means that we are indexing along the second dimension of `x`. In this case, `x` has 2 dimensions and the size of each dimension is 3. The first dimension corresponds to the number of rows in the tensor and the second dimension corresponds to the number of columns\n",
    "\n",
    "- The `index` parameter specifies which indices to select. In this case, `indices` contains the values `0`, `1`, and `2`, so `torch.gather` will select the elements at indices `0`, `1`, and `2` along the second dimension of `x`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a8e8b9bb-657f-4b6d-9840-2ea16fe4ca37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [5],\n",
       "        [9]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3bc523-a467-46c6-9dd7-35700e64b1f8",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc4554fe-6ca8-47d5-a601-72dde1d74285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "44e5f49e-ef59-4d09-9a41-0e11cfc61f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2333, -0.1872, -3.2762,  ..., -2.9148, -5.0910, -1.0786],\n",
       "         [ 2.4011,  3.5135, -1.9742,  ..., -7.9800, -1.3352,  0.3985],\n",
       "         [ 0.3600,  0.7970, -3.2943,  ..., -5.8384, -3.4494, -0.4427],\n",
       "         [ 1.2610,  2.0624, -2.2482,  ..., -6.9114, -8.1211, -1.2510],\n",
       "         [ 0.2554,  0.5884, -2.6440,  ..., -6.0750, -7.4630, -0.4967]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b240d53-4a84-4b7f-a625-337703fdb8a7",
   "metadata": {},
   "source": [
    "Explain\n",
    "- `[1]`: First applying the softmax function to the logits tensor, which converts the logits into probabilities that sum to 1. The softmax is taken along the last dimension of the logits tensor, which is specified by the dim argument\n",
    "- `[2]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77b6fd32-99cf-4b8a-a9a3-821f81011ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probs_from_logits(logits, labels=None):\n",
    "    indices = labels.unsqueeze(2\n",
    "                              )\n",
    "    probs = F.softmax(logits, dim=-1) # [1]\n",
    "    log_probs = probs.log() # [2]\n",
    "    \n",
    "    log_prob_labels = torch.gather(lop_probs, indices).squeeze(-1)\n",
    "    return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "444dd797-a446-43c4-a6f2-3fbefc0a472f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-11.1238, -10.0776, -13.1667,  ..., -12.8053, -14.9814, -10.9691],\n",
       "         [ -8.3411,  -7.2288, -12.7165,  ..., -18.7223, -12.0775, -10.3438],\n",
       "         [-11.1479, -10.7109, -14.8022,  ..., -17.3463, -14.9573, -11.9506],\n",
       "         [-11.4963, -10.6949, -15.0055,  ..., -19.6687, -20.8785, -14.0083],\n",
       "         [-11.5677, -11.2347, -14.4671,  ..., -17.8981, -19.2861, -12.3198]]],\n",
       "       device='cuda:0', grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs_from_logits(output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb61c07-b63a-4b33-b532-74c2540e2d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10233a-0bf0-4a49-b79d-b46f057e2cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
