{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d336ed14-633e-40e5-be1e-723cb4eb6c8a",
   "metadata": {},
   "source": [
    "# 1. Large Datasets and Where to Find Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7d3b9d0-c7fa-416c-aa64-2378338ee9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5518db2-721e-4109-a592-e82fc3466d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442786ac8d6742b3bde3151f875cbab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/656 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c121ddc487bc4af1ad0afb4d01c99d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/457M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OpenAIGPTLMHeadModel were not initialized from the model checkpoint at openai-gpt and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fdcfbc0c7248f3bba5afe7abf0d97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070fb84bda484ac68a61edfdee5aefbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/448k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad00f7f9d44465281b8bc4c6322479a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_gpt = pipeline(\"text-generation\", model=\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4779ba-3a7c-4155-a9a6-774e88389b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5dd263-87c8-420d-8656-9341202938fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code = r\"\"\"def say_hello():\n",
    "      print(\"Hello, World!\")\n",
    "# Print it\n",
    "say_hello()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec8d203f-bf13-4b8b-a4f5-e874848e67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92065ec3-0dc5-4f15-ac0b-514ee0476377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ġsay',\n",
       " '_',\n",
       " 'hello',\n",
       " '():',\n",
       " 'Ċ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġprint',\n",
       " '(\"',\n",
       " 'Hello',\n",
       " ',',\n",
       " 'ĠWorld',\n",
       " '!\"',\n",
       " ')',\n",
       " 'Ċ',\n",
       " '#',\n",
       " 'ĠPrint',\n",
       " 'Ġit',\n",
       " 'Ċ',\n",
       " 'say',\n",
       " '_',\n",
       " 'hello',\n",
       " '()',\n",
       " 'Ċ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(python_code).tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27cb471-5248-44a0-be44-d32b537212b3",
   "metadata": {},
   "source": [
    "# 2. Building a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1885a5b9-5926-456f-a69d-88b4d2dfd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, e = u\"a\", u\"€\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889612f0-6a77-42e6-91b6-a2dd81715c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "byte = ord(a.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278e8a8c-247c-47b1-8bc8-aa64ba0deada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f80cc5a-7534-49a9-9c06-5514f8d547f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "byte = [ord(chr(i)) for i in e.encode(\"utf-8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc6b239f-16d1-4bee-ab3a-7d47b914824a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[226, 130, 172]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19fe7bf0-cd1f-462d-bee6-2c9d8da9cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.tokenization_gpt2 import bytes_to_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1322f22-2c1b-4e7a-a8b9-730c9a1d0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "byte_to_unicode_map = bytes_to_unicode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b2f325-af5e-472d-8683-628c8b6ffd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_to_byte_map = dict((v, k) for k, v in byte_to_unicode_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e6f779-f03e-4e01-9994-40213d31cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unicode_to_byte_mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a6f9dcb-1269-43f3-86da-2d61b0f38ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vocab = list(unicode_to_byte_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff81d134-62b3-4511-be03-19e9826ec5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01866432-69df-4971-8df5-e0ec0f86fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(tokenizer.vocab.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f1cbd88-9657-43eb-a862-833a4ab08cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'!'}, {'\"'}, {'#'}, {'$'}, {'%'}, {'&'}, {\"'\"}, {'('}, {')'}, {'*'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{tokenizer.convert_tokens_to_string(t)} for t, _ in tokens[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c94b190f-d911-46c4-afd1-eafd09963cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efd24ac-41b1-40fc-9ee6-18a111d4e9a4",
   "metadata": {},
   "source": [
    "### new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658017f1-b4b3-4db4-9f7f-0cf1f2c479f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.tokenization_gpt2 import bytes_to_unicode\n",
    "\n",
    "byte_to_unicode_map = bytes_to_unicode()\n",
    "unicode_to_byte_map = dict((v, k) for k, v in byte_to_unicode_map.items())\n",
    "base_vocab = list(unicode_to_byte_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc31a2b-b29c-4a8e-aa61-9102c2173d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d0a78a-1442-419d-9c8c-4845d5d134bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebd0abf-b4cc-4ad2-9c8a-fbe48aa1ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"transformersbook/codeparrot-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15941b5b-2f31-44fe-9980-62da37abe04a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[43mdataset_name\u001b[49m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, streaming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_name' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9f745-e099-49c0-8628-0740898da0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dataset = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f442763-c4d8-45fa-b251-cefe4babc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterator(batch_size=10):\n",
    "    for _ in tqdm(range(0, length, batch_size)):\n",
    "        yield [next(iter_dataset)['content'] for _ in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de0ac5-633a-49be-9b54-7d73ec37a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf770d18-da4c-4d19-8b03-ede7f867df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer = tokenizer.train_new_from_iterator(\n",
    "    batch_iterator(),\n",
    "    vocab_size=12500,\n",
    "    initial_alphabet=base_vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b6939-33a9-47af-9b86-1ea9c610e7cc",
   "metadata": {},
   "source": [
    "### Training a Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f5aad67-4cf4-4c7d-a51b-87b73b8f8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d91c52e2-29ec-441a-82c9-6088f842f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"gpt2-xl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0e80636-732a-47d9-9b9e-5133757dc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "633d7c92-3068-4bf0-8035-5857b5a1bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"gpt2-xl\", vocab_size = len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44eb45a0-c9f6-434d-82b0-596ed337a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2-xl\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1600,\n",
       "  \"n_head\": 25,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 48,\n",
       "  \"n_positions\": 1024,\n",
       "  \"output_past\": true,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a5d0438-7d5a-48d7-8690-6bcc2d26605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "143e3507-665b-4bef-a9a6-d0c5185a6ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, total_characters, total_tokens = 500, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "788573f9-8552-4366-84a6-7c0f3970e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration transformersbook--codeparrot-train-39fd2cee2b2cb397\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"transformersbook/codeparrot-train\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9a95359-76bc-42b7-bec6-cb7e5fb4de98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<02:41,  3.09it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 500/500 [00:06<00:00, 78.63it/s] \n"
     ]
    }
   ],
   "source": [
    "for _, example in tqdm(zip(range(examples), iter(dataset)), total=examples):\n",
    "    total_characters += len(example[\"content\"])\n",
    "    total_tokens += len(tokenizer(example[\"content\"]).tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad3d5749-5e89-415e-a207-d703f3eeaeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5568371"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71c26e90-9c55-42bb-9e56-879aaddec48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2527740"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f22d5e0a-7b42-40fb-af76-01dd57af9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361bc9a-ac3c-40de-8d8a-5d8bf4dcf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConstantLengthDataset(IterableDataset):\n",
    "#     def __init__(\n",
    "#         self, tokenizer, dataset, seq_length=1024,\n",
    "#         num_of_sequences=1024, chars_per_token=3.6\n",
    "#     ):\n",
    "#         self.tokenizer = tokenizerenizer\n",
    "#         self.concat_token_id = tokenizer.eos_token_id\n",
    "#         self.dataset = dataset\n",
    "#         self.seq_length = seq_length\n",
    "#         self.input_characters = seq_length * char_per_token * num_of_sequences\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         iterator = iter(self.dataset)\n",
    "#         more_examples = True\n",
    "        \n",
    "#         while more_examples:\n",
    "#             buffer, buffer_len = [], 0\n",
    "            \n",
    "#             while True:\n",
    "#                 if buffer_len >= self.input_characters:\n",
    "#                     m = f\"Buffer full: {}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "102e6300-9bd4-46db-b35f-9d812e06d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantLengthDataset(IterableDataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, dataset, seq_length=1024,\n",
    "                 num_of_sequences=1024, chars_per_token=3.6):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.concat_token_id = tokenizer.eos_token_id\n",
    "        self.dataset = dataset\n",
    "        self.seq_length = seq_length\n",
    "        self.input_characters = seq_length * chars_per_token * num_of_sequences\n",
    "    \n",
    "    def __iter__(self):\n",
    "        iterator = iter(self.dataset)\n",
    "        more_examples = True\n",
    "        while more_examples:\n",
    "            buffer, buffer_len = [], 0\n",
    "            while True:\n",
    "                if buffer_len >= self.input_characters:\n",
    "                    m=f\"Buffer full: {buffer_len}>={self.input_characters:.0f}\"\n",
    "                    print(m)\n",
    "                    break\n",
    "                try:\n",
    "                    m=f\"Fill buffer: {buffer_len}<{self.input_characters:.0f}\"\n",
    "                    print(m)\n",
    "                    buffer.append(next(iterator)[\"content\"])\n",
    "                    buffer_len += len(buffer[-1])\n",
    "                except StopIteration:\n",
    "                    iterator = iter(self.dataset)\n",
    "\n",
    "            all_token_ids = []\n",
    "            tokenized_inputs = self.tokenizer(buffer, truncation=False)\n",
    "            for tokenized_input in tokenized_inputs['input_ids']:\n",
    "                all_token_ids.extend(tokenized_input + [self.concat_token_id])\n",
    "            \n",
    "            for i in range(0, len(all_token_ids), self.seq_length):\n",
    "                input_ids = all_token_ids[i : i + self.seq_length]\n",
    "                if len(input_ids) == self.seq_length:\n",
    "                    yield torch.tensor(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "feb2751b-6870-4dba-800f-c4910abe0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = dataset.shuffle(buffer_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf7219-3cf8-4be2-ae66-a8009ed3976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_length_dataset = ConstantLengthDataset(\n",
    "    tokenizer, shuffled_dataset,\n",
    "    num_of_sequences=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab58c3a-d345-4496-9ae1-ed6c755c96e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'constant_length_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconstant_length_dataset\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'constant_length_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "constant_length_dataset.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc75a3-c27d-4b24-af6e-0353e9388307",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iterator = iter(constant_length_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb26dad-f929-4881-8728-619666f4ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(b) for _, b in zip(range(5), dataset_iterator)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616372f-39a2-4e65-858a-ef18e689deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216e530-a910-44ea-bf9e-00620ad5e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(dataset_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d088392-7faa-446a-b053-a1f06fa87017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "# Commented parameters correspond to the small model\n",
    "config = {\"train_batch_size\": 2, # 12\n",
    "          \"valid_batch_size\": 2, # 12\n",
    "          \"weight_decay\": 0.1,\n",
    "          \"shuffle_buffer\": 1000,\n",
    "          \"learning_rate\": 2e-4, # 5e-4\n",
    "          \"lr_scheduler_type\": \"cosine\",\n",
    "          \"num_warmup_steps\": 750, # 2000\n",
    "          \"gradient_accumulation_steps\": 16, # 1\n",
    "          \"max_train_steps\": 50000, # 150000\n",
    "          \"max_eval_steps\": -1,\n",
    "          \"seq_length\": 1024,\n",
    "          \"seed\": 1,\n",
    "          \"save_checkpoint_steps\": 50000} # 15000\n",
    "\n",
    "args = Namespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6d0d902-4f9e-4ff1-9e57-9cb395fc4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76427c21-1a95-45c6-aa18-0594f72f99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataset_name):\n",
    "    train_data = load_dataset(\n",
    "        dataset_name+'-train',\n",
    "        split=\"train\", streaming=True\n",
    "    )\n",
    "    valid_data = load_dataset(\n",
    "        dataset_name+'-valid',\n",
    "        split=\"validation\", streaming=True\n",
    "    )\n",
    "    \n",
    "    train_data = train_data.shuffle(\n",
    "        buffer_size=args.shuffle_buffer,\n",
    "        seed=args.seed\n",
    "    )\n",
    "    \n",
    "    train_dataset = ConstantLengthDataset(\n",
    "        tokenizer, train_data, seq_length=args.seq_length\n",
    "    )\n",
    "    valid_dataset = ConstantLengthDataset(\n",
    "        tokenizer, valid_data, seq_length=args.seq_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f31a32-89b6-41fa-a0f3-f5d15fb11778",
   "metadata": {},
   "source": [
    "### Results and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a01bb41-771e-4a51-8193-5795a71c9c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29373acf-10bb-40f9-a1fa-656ddf974d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"transformersbook/codeparrot-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e94f5e1f-dc24-4862-8409-cba56e61df29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0faa803b2d48559dc1723c2cb883ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/865 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de15592224e4eeb92d915330a3cb995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fd15f2057b4d10855b057677a55c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc5dcbf01d24666871381c4fbbbcb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/485k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4ca5071f94458cbbe5a033114888f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/270k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e635c9656be4a3da8933b3d033a88de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/821k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1eba1fc3c844b0816b29e915b0fd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation = pipeline(\"text-generation\", model=model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca3f00f1-a01b-4eb9-b094-e50209cce63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b8f7b97-930c-4dd3-a68f-97b5e2515c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_block(string):\n",
    "    return re.split('\\nclass|\\ndef|\\n#|\\n@|\\nprint|\\nif', string)[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a608848d-c861-4bec-8410-8f48f5170aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_code(pipe, promopt, max_length=64, num_completions=4):\n",
    "    gen_kwargs = {\n",
    "        \"temperature\": 0.4,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 0,\n",
    "        \"num_beams\": 1,\n",
    "        \"do_sample\": True\n",
    "    }\n",
    "    \n",
    "    code_gens = generation(\n",
    "        prompt, num_return_sequences=num_completions,\n",
    "        max_length=max_length, **gen_kwargs\n",
    "    )\n",
    "    \n",
    "    code_strings = []\n",
    "    for code_gen in code_gens:\n",
    "        generated_code = first_block(code_gen[\"generated_text\"][len(prompt):])\n",
    "        code_strings.append(generated_code)\n",
    "    print(('\\n'+'='*80 + '\\n').join(code_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51348bfb-918a-4ff7-aed3-1481fc4d1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''def area_of_rectangle(a: float, b: float):\n",
    "      \"\"\"Return the area of the rectangle.\"\"\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "372fa70c-4d95-4695-9126-a2d4374eb522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      return a / b\n",
      "\n",
      "  def area_of_rectangle_area(a: float, b: float):\n",
      "      \"\"\"Return the area of the rectangle area.\"\"\"\n",
      "      return a / b\n",
      "\n",
      "  def\n",
      "================================================================================\n",
      "\n",
      "      return a / b\n",
      "\n",
      "  def area_of_rectangle_from_rectangle(a: float, b: float):\n",
      "      \"\"\"Return the area of the rectangle from a rectangle.\"\"\"\n",
      "      return a\n",
      "================================================================================\n",
      "\n",
      "      return self.area_of_rectangle(a, b)\n",
      "\n",
      "  def area_of_rectangle(self, a: float, b: float):\n",
      "      \"\"\"Return the area of the rectangle\n",
      "================================================================================\n",
      "\n",
      "      return a * b\n",
      "\n",
      "  def area_of_rectangle_in_polygon(a: float, b: float):\n",
      "      \"\"\"Return the area of the rectangle in polygon.\"\"\"\n",
      "      return a *\n"
     ]
    }
   ],
   "source": [
    "complete_code(generation, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e029605-705d-4ee7-9a8e-7e5cc6c75cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944e33f-887f-403c-b62e-b3c8292b4189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
