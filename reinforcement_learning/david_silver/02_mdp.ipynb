{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c73c2-2f13-45f9-810f-8641fabbb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import numpy as np\n",
    "\n",
    "# Define the dimensions of the MDP\n",
    "num_states = 3\n",
    "num_actions = 2\n",
    "\n",
    "# Define the transition matrix\n",
    "transition_matrix = np.array([\n",
    "    [[0.7, 0.3], [0.4, 0.6]],\n",
    "    [[0.1, 0.9], [0.2, 0.8]],\n",
    "    [[0.2, 0.8], [0.1, 0.9]],\n",
    "])\n",
    "\n",
    "# Define the reward matrix\n",
    "reward_matrix = np.array([\n",
    "    [[5, 10], [1, 2]],\n",
    "    [[3, 6], [2, 4]],\n",
    "    [[1, 2], [3, 6]],\n",
    "])\n",
    "\n",
    "# Define the discount factor\n",
    "discount_factor = 0.9\n",
    "\n",
    "# Define the initial state\n",
    "initial_state = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6205d-109f-428d-8aa4-2820d33d0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state to calculate the value for\n",
    "state = 0\n",
    "\n",
    "# Initialize the value to zero\n",
    "value = 0\n",
    "\n",
    "# Loop over the actions available in the state\n",
    "for action in range(num_actions):\n",
    "    # Initialize the expected reward to zero\n",
    "    expected_reward = 0\n",
    "    \n",
    "    # Loop over the possible next states\n",
    "    for next_state in range(num_states):\n",
    "        # Calculate the expected reward for the state-action pair\n",
    "        expected_reward += transition_matrix[state][action][next_state] * reward_matrix[state][action][next_state]\n",
    "    \n",
    "    # Calculate the value for the state-action pair\n",
    "    value += expected_reward * discount_factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7eea3-7165-47a7-9d21-ffcae4aafe09",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79bcdebd-235c-45d1-a265-6f629a142a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1530daf-9333-4a07-8704-aa71a1ea93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = torch.tensor([\n",
    "    [0.7, 0.2, 0.1],\n",
    "    [0.1, 0.6, 0.3],\n",
    "    [0.2, 0.3, 0.5]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae058bb5-3c57-43d3-b9dc-cb8dd3dd4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.tensor([\n",
    "    [0, 0, 1],\n",
    "    [0, 0, -1],\n",
    "    [0, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1400de2-0819-47f9-87c7-abff986a7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_dist = torch.tensor([0.5, 0.5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944dcab4-70be-4432-a015-347310eb421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e7e84ea-2f26-42ad-ab78-d8d2cbe0cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = torch.tensor([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91828794-578e-46da-b03e-524264798e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = torch.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cb0d197-11ec-40be-8708-b7d765a6fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = rewards + gamma * torch.mm(transition_probs, values.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b8e1b3a-d7c5-4605-89e5-fa300d5987f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  1.],\n",
       "        [ 0.,  0., -1.],\n",
       "        [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003e1b4-b577-47f4-bf8d-4e34a129e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    values = rewards + gamma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
