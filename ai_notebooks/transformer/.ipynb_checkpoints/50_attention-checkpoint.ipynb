{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0f8dfa-7256-4fb3-b5c4-cc4156db674a",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "788b3e71-2535-4c22-8407-ba1a8bff654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814a7d4-9311-40a4-b2d8-f9bbdebfd5c1",
   "metadata": {},
   "source": [
    "$\\operatorname{Attention}(Q, K, V)= Z =\\operatorname{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3bf9d0-b61e-451b-9e57-2fefefec3677",
   "metadata": {},
   "source": [
    "Write a function that calculate the attention, return the output $Z$ and attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8e81739-b4f4-473c-85ea-660a440f7cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V, d_k):\n",
    "    QK = torch.matmul(Q, K.T)\n",
    "\n",
    "    matmul_scaled = QK / math.sqrt(d_k)\n",
    "\n",
    "    attention_weights = F.softmax(matmul_scaled, dim=-1)\n",
    "    \n",
    "    output = torch.matmul(attention_weights, V)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb7240-62d1-46ae-8f78-83a273d5e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, attention_weights = scaled_dot_product_attention(Q, K, V, d_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed92021-d810-431a-94ba-d0670c484b2b",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64b03303-2366-4caf-af2e-a4eda4158dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_k = torch.Tensor([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]])  # (4, 3)\n",
    "\n",
    "temp_v = torch.Tensor([[   1,0, 1],\n",
    "                      [  10,0, 2],\n",
    "                      [ 100,5, 0],\n",
    "                      [1000,6, 0]])  # (4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39f4aa13-6035-4697-ab35-7fec76f9be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_q = torch.Tensor([[0, 10, 0]])  # (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd44f3-9e78-4207-b34b-b6d87c559e7a",
   "metadata": {},
   "source": [
    "`scaled_dot_product_attention` is a function calculate the self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff73aa7f-45a1-4fc4-85b6-a031f23432e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0., 10.,  0.]]),\n",
       " tensor([[10.,  0.,  0.],\n",
       "         [ 0., 10.,  0.],\n",
       "         [ 0.,  0., 10.],\n",
       "         [ 0.,  0., 10.]]),\n",
       " tensor([[   1.,    0.,    1.],\n",
       "         [  10.,    0.,    2.],\n",
       "         [ 100.,    5.,    0.],\n",
       "         [1000.,    6.,    0.]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_q, temp_k, temp_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d8252d5-0aae-4582-bc16-1de8b5470d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, attention_weights = scaled_dot_product_attention(temp_q, temp_k, temp_v, d_k = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be3d3e41-e85a-420b-bcf9-404185c85d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 0., 0.]]), torch.Size([1, 4]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(attention_weights, decimals=3), attention_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5047ce-7408-41cf-8ccd-e01cb418979c",
   "metadata": {},
   "source": [
    "Interpret the output of `attention_weights`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453dc5b9-318a-4393-8f41-597408d4de58",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "- Given vector `temp_q`: `[ 0., 10.,  0.]`\n",
    "- It will find all `4` vectors in `temp_k` that similar to `temp_q` by the dot product\n",
    "    + High value => similar\n",
    "    + Low value => not similar\n",
    "- The output of `attention_weights` is `1 x 4`: each row represent the similar between each vector in `temp_k` to `temp_q`\n",
    "    + Position `0`, `2` and `3` are zeros => no similar - (1)\n",
    "    + Position `1` is highest value => similar - (2)\n",
    "\n",
    "**Conclusion**\n",
    "- `temp_k[0]`, `temp_k[2]`, `temp_k[3]` are not similar to `temp_q` - (1)\n",
    "- `temp_k[1]` is similar to `temp_q` - (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36f6e5d-0b56-4f68-8f40-6c04eb01a9c8",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d59a8b1-9364-4113-80e2-c45873e4a58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  0.,  2.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(output, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e46c36d-7074-4be6-8d93-b8a3cc1f0a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44fe016c-9a14-4b57-8cc3-918b3564da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 4\n",
    "d_h = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc3e95-a684-42f7-91e9-74889143938f",
   "metadata": {},
   "source": [
    "https://youtu.be/1BFE1Tfs8tM?t=1928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d41517c-f012-4a23-97c1-6f390163f84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
