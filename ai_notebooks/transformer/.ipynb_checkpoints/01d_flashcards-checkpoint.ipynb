{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d590d3cc-bd55-4102-b926-5a1ae6e6b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551ca770-bc80-439b-811e-af8c94cfc8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # shape(Q) = [B x num_heads x Q_len x D/num_heads]\n",
    "        # shape(K, V) = [B x num_heads x KV_len x D/num_heads]\n",
    "\n",
    "        # reshaped(K) = [B x num_heads x D/num_heads x KV_len]\n",
    "        Q_K_matmul = torch.matmul(Q, K.permute(0, 1, 3, 2))\n",
    "        scores = Q_K_matmul/math.sqrt(self.d_model)\n",
    "        # shape(scores) = [B x num_heads x Q_len x KV_len]\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        # shape(attention_weights) = [B x num_heads x Q_len x KV_len]\n",
    "\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "        # shape(output) = [B x num_heads x Q_len x D/num_heads]\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aeacca-8852-47ff-913f-d1ff33c666cc",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d1a3ff-0ec2-4db7-b400-543e7e40bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41f70f8-1b5c-4ab3-8b71-f69e13f5a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model, n_heads = 24, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11188c6c-e2f7-4fb1-9ada-75e705e42271",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_head = 24 // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c5b090-c447-4611-84d0-d8762b24207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention = SelfAttention(d_model=d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22381736-455d-4a4c-8c5e-473775bc8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, v = torch.randn(batch_size, n_heads, 3, d_head), torch.randn(batch_size, n_heads, 3, d_head), torch.randn(batch_size, n_heads, 3, d_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "150e9bce-7ff8-4daf-8763-562fe9db607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e552d-c71a-4f06-b655-39fe968f998f",
   "metadata": {},
   "source": [
    "Write a scale product self-attention that **uses in multi-head attention** from scratch\n",
    "\n",
    "**Hints**\n",
    "- The valid shape of matrix multiplication: `[10, 4, x, y]` @ `[10, 4, y, x]`\n",
    "- Scores divide by (the square root of the dimension of a word embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8826ff88-0d15-4ce7-9955-11e1c661aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        # shape(q, k, v) = [batch_size x num_heads x seq_len x d_model/n_heads]\n",
    "\n",
    "        # reshaped(k) = [batch_size x num_heads x d_model/n_heads x seq_len]\n",
    "        reshaped_k = k.permute(0, 1, 3, 2)\n",
    "                \n",
    "        Q_K_matmul = torch.matmul(q, reshaped_k)\n",
    "        # shape(scores) = [batch_size x num_heads x q_len x kv_len]\n",
    "        scores = Q_K_matmul / math.sqrt(self.d_head)\n",
    "\n",
    "        # shape(attention_weights) = [batch_size x n_heads x q_len x kv_len]\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # shape(output) = [batch_size x n_heads x q_len x d_model/n_heads]\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946b8ca-4f94-44f5-b1d4-fcf4e1f040c6",
   "metadata": {},
   "source": [
    "`q` contains `10` sentences, each sentence has `3` words. And there're `4` heads. Same for `k` and `v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8a5fb5a-7700-4da0-b2d3-bef6c4fbf54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 4, 3, 6]),\n",
       " torch.Size([10, 4, 3, 6]),\n",
       " torch.Size([10, 4, 3, 6]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14f1c6d3-6511-4d98-8401-cb66c2646447",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'd_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m self_attention \u001b[38;5;241m=\u001b[39m \u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'd_model'"
     ]
    }
   ],
   "source": [
    "self_attention = SelfAttention(d_model=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a3874-2fe4-4c5b-a535-e3b3badddb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, attention_weights = self_attention(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "594b8aca-901b-4129-b621-277d5c90c722",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241m.\u001b[39mshape, attention_weights\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d5b63-fade-48fc-b54a-b34bc2e70854",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df2cbdd-67ea-42ac-9b59-af3ff9006c11",
   "metadata": {},
   "source": [
    "Write an efficient multi-head attention (one matrix for all heads) from scratch in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5b99804-f3ae-4d2d-9730-459c580d1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, attention, d_model, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        # d_q, d_k, d_v\n",
    "        self.d = d_model//num_heads\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attention = attention\n",
    "\n",
    "        self.linear_Q = nn.Linear(d_model, d_model)\n",
    "        self.linear_K = nn.Linear(d_model, d_model)\n",
    "        self.linear_V = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.mha_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, pre_q, pre_k, pre_v, mask=None):\n",
    "        # shape(x) = [B x seq_len x D]\n",
    "\n",
    "        Q = self.linear_Q(pre_q)\n",
    "        K = self.linear_K(pre_k)\n",
    "        V = self.linear_V(pre_v)\n",
    "        # shape(Q) = [B x seq_len x D] (if in encoder, seq_len = SRC_seq_len; if in decoder, seq_len = TRG_seq_len)\n",
    "        # shape(K, V) = [B x seq_len x D] (always SRC_seq_len unless in masked-multihead-attention)\n",
    "\n",
    "        batch_size = pre_q.shape[0]\n",
    "\n",
    "        Q = Q.reshape(batch_size, self.num_heads, -1, self.d)\n",
    "        K = K.reshape(batch_size, self.num_heads, -1, self.d)\n",
    "        V = V.reshape(batch_size, self.num_heads, -1, self.d)\n",
    "        # shape(Q) = [B x num_heads x seq_len x D]\n",
    "        # shape(K, V) = [B x num_heads x seq_len x D]\n",
    "\n",
    "        # run scaled_dot_product_attention\n",
    "        output, attn_weights = self.attention(Q, K, V)\n",
    "        # shape(output) = [B x num_heads x Q_len x D/num_heads]\n",
    "        # shape(attn_weights) = [B x num_heads x Q_len x KV_len]\n",
    "\n",
    "        output = output.reshape(batch_size, -1, self.d_model)\n",
    "        # shape(output) = [B x seq_len x D]\n",
    "\n",
    "        projection = self.dropout(self.mha_linear(output))\n",
    "\n",
    "        return projection, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf5214d2-ecc3-4ec8-a42e-9b0ef12336eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f33c8de6-4ca6-4466-b755-46029773d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = SelfAttention(d_head=d_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dc8a2a1-b239-4461-8a38-498d739c011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(\n",
    "    attention=attention,\n",
    "    d_model=d_model, num_heads=2,\n",
    "    dropout=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f90a8b98-8e44-42a7-88a5-c9ea719e31ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_q = torch.randn(1, 3, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cdfa7fa-7a5b-4d2f-a0d2-ee28f61dd2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_k = torch.randn(1, 3, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c632872f-1be7-4f6d-8cce-b3210abb9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_v = torch.randn(1, 3, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92187a6e-ba34-428d-9116-b629c418f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection, attention_weights = mha(\n",
    "    pre_q=pre_q, pre_k=pre_k, pre_v=pre_v\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1329097-74c2-427f-9d51-701928696ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 6]), torch.Size([1, 2, 3, 3]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb925a3-a001-4757-a87a-815a8f1e1a84",
   "metadata": {},
   "source": [
    "##### Example 2.2: Better variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a72e9f37-ae19-4f5d-9f98-2a10872a2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_q = torch.randn(10, 3, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "feebf836-259c-4d6e-a046-4905499115d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_k = torch.randn(10, 3, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b08e58cf-2a9f-4273-b712-c6ab2a757c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_v = torch.randn(10, 3, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ca43682-de61-4bb3-9c81-3e42222f7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95eb803c-afdf-468a-aa29-8abf15126ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model, self.n_heads = d_model, n_heads\n",
    "        self.attention = attention\n",
    "        self.d_head = d_model // n_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.w_k = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.w_v = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.mha_linear = nn.Linear(n_heads * self.d_head, d_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        return x.view(batch_size, self.n_heads, seq_len, self.d_head)\n",
    "    \n",
    "    def concat(self, x):\n",
    "        batch_size, n_heads, seq_len, d_head = x.size()\n",
    "        d_model = n_heads * d_head\n",
    "        return x.view(batch_size, seq_len, d_model)\n",
    "\n",
    "    def forward(self, pre_q, pre_k, pre_v):\n",
    "        # shape(q, k, v) = [batch_size x seq_len x d_model]\n",
    "        q, k, v = self.w_q(pre_q), self.w_k(pre_k), self.w_v(pre_v)\n",
    "\n",
    "        # shape(v, k, v) = [batch_size x n_heads x seq_len x d_model]\n",
    "        k, v, q = self.split_heads(k), self.split_heads(v), self.split_heads(q)\n",
    "\n",
    "        # shape(output) = [batch_size x n_heads x q_len x d_model/n_heads]\n",
    "        # shape(attn_weights) = [batch_size x n_heads x q_len x kv_len]\n",
    "        output, attn_weights = self.attention(q, k, v)\n",
    "        \n",
    "        # shape(output) = [batch_size x seq_len x d_model]\n",
    "        output = self.concat(output)\n",
    "        projection = self.mha_linear(output)\n",
    "        return projection, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a661172-08c2-43f0-839e-e0a145461e9c",
   "metadata": {},
   "source": [
    "Write an efficient multi-head attention (one matrix for all heads) from scratch in pytorch\n",
    "\n",
    "**Hints**\n",
    "- `SelfAttention` takes `q, k, v` as input in forward pass\n",
    "- The last linear layer in multi-head attention has shape `(d_model, d_model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2214231-567f-4edd-95e1-90db31682e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc2b5905-9092-48d9-9d9a-4c0d14ff443a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'd_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'd_model'"
     ]
    }
   ],
   "source": [
    "attention = SelfAttention(d_model=d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2426199-cedf-4af2-8b0c-840cc921e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(\n",
    "    attention=attention,\n",
    "    d_model=d_model, n_heads=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ab3f8-83c9-4461-a58b-bfd17592a4a4",
   "metadata": {},
   "source": [
    "`pre_q` is a batch of `10` sentence, each sentece include `3` words. Same for `pre_k` and `pre_v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4320ed9-4dc6-4e0f-8585-adfa62f23c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 6]), torch.Size([10, 3, 6]), torch.Size([10, 3, 6]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_q.shape, pre_k.shape, pre_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b2d87035-a61d-47aa-8788-3a6445dba506",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection, attention_weights = mha(\n",
    "    pre_q=pre_q, pre_k=pre_k, pre_v=pre_v\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "2bb43964-5382-4641-99c7-d99aba49fbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 6]), torch.Size([10, 2, 3, 3]))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f72e321-6283-4cc7-8dbc-2663f5f6b582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37bffe6-76a5-4e4f-b377-68aa310d90ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
