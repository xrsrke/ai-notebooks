{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab375f63-5c91-4f93-a2c8-2b7944dce1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65349a6-6969-43d1-89fb-a89392af38d5",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c2ca3b-3ca3-4f4f-a111-7d7976682682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723f26c4-d0bc-43ae-83de-c1256b9a90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c396b8-72e5-4858-a87a-6b9e7ad8aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16(weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff03072-f1d2-4e9a-84db-a1ffe0155d6c",
   "metadata": {},
   "source": [
    "`model` is a pre-trained VGG-16.\n",
    "\n",
    "Do transfer learning to classify 10 labels. Explain each step why you do it (4 steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0389e-6fd8-4a2c-9f69-81bde039685a",
   "metadata": {},
   "source": [
    "**Step 1**: Freeze all the convolution layers because it's trained to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de207ad-122f-48f5-b697-e6f63c7b49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9dae2-74cd-433f-98ec-9b78818f779b",
   "metadata": {},
   "source": [
    "**Step 2**: Enable calculate gradient in the first and second linear layer\n",
    "\n",
    "Because these layer will learn the map function from features to target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd861d9d-b9f3-42b5-8b5d-8bf2c0152db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[0].requires_grad = True\n",
    "model.classifier[3].requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a95bb7d-ab77-43de-9ff1-a4c7ce4abfb6",
   "metadata": {},
   "source": [
    "**Step 3**: Replace the final linear layer to output 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbf29fed-859c-4924-97d6-a4a52865bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Linear(4096, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9816d650-b19a-4dd4-b6ef-871906178a20",
   "metadata": {},
   "source": [
    "**Step 4**: Train like normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabd6c9-a944-4c88-b3eb-80b3729b0ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
