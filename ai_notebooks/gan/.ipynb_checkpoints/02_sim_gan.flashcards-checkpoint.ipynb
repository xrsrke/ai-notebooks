{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28e0b922-0ecc-4a58-a3e6-9eec72696bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ad012a9-5568-4a4c-b840-4190caac007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a81c568c-5138-4d71-8219-14c2c3180fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c5ecc-e588-4e7b-a34c-bba97f32f8a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Exampel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8f2cf1b-03eb-482c-afe9-68de70b0d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97d1cf52-f95f-4db2-a739-a251804cda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b06a693-0a58-4bf9-bb06-3b02281c618f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2ffd7-8b24-48e2-9f9e-c97405a189c6",
   "metadata": {},
   "source": [
    "Flatten the tensor `x` without specify specifically how to do it.\n",
    "\n",
    "Hint: use `.view`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52e0f13e-f8e2-4450-a875-776d1fd879da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111050a-eb54-431f-93a9-daa066e7f033",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a528f14-dd6e-44ee-a662-770b3c3e4a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cf6a5fe-ea0f-49ba-b643-af4c5696d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82c4d924-cd5f-4134-91d2-759057468388",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_evaluated_of_fake = F.sigmoid(torch.randn(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8bb050-766d-4d29-ab01-6e4073c12c1b",
   "metadata": {},
   "source": [
    "`criterion` is the loss function for the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1891a937-7b88-4d54-a379-ebe477696f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6aacf3-f89b-4de1-b5b9-45591c486d9e",
   "metadata": {},
   "source": [
    "`disc_evaluated_of_fake` is the evaluation of the discriminator given 10 fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "861ea43d-2d69-478e-8534-d994b57771c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_evaluated_of_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79324a22-ed15-4917-a7c9-27b520ccc39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8098, 0.3384, 0.4377, 0.2367, 0.1716])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_evaluated_of_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621f374-5a26-44a0-8a95-63c46bebbe42",
   "metadata": {},
   "source": [
    "Create a function that calculate the loss of the dicriminator given the fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf5c2ca4-8dbc-4767-b993-9bd356fe67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_of_fake(loss_func, evaluated):\n",
    "    actual_evaluation = torch.zeros_like(evaluated)\n",
    "    return loss_func(evaluated, actual_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e8fed72-9652-41d4-bee4-7f7ab589a04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6213)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_of_fake(loss_func=criterion, evaluated=disc_evaluated_of_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27359dff-124d-423f-a473-c834f8dda8d8",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "475e173a-3882-4965-ad28-76cebd280a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossD_real = torch.tensor(3.31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "91bea85d-421d-4393-80f2-a7d88651af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossD_fake = torch.tensor(94.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e36a99-5862-4747-966f-d92c2a1922db",
   "metadata": {},
   "source": [
    "`lossD_real` is the loss of the discriminator given real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f70ee360-ee13-4322-9c75-de9c65aed7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3100)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossD_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182afed-5088-4802-9499-e976d45ebfdf",
   "metadata": {},
   "source": [
    "`lossD_fake` is the loss of the discriminator given fake image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7fd888e0-6d7a-4698-a8fe-f1588a030c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(94.2000)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossD_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9818e04a-b5dc-4e74-8e11-2c702ae0ad1f",
   "metadata": {},
   "source": [
    "Write a function calculate the loss of the discriminator that will be use to do the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2695a1a4-c72a-47cf-953b-e9e0bc222520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(loss_real, loss_fake):\n",
    "    return (loss_real + loss_fake) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d52a9ae-aa5f-479a-a535-1bc176beb458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48.7550)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(lossD_real, lossD_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079f326-d6b1-43f2-866b-dd91ca940439",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f5b8a-a17a-4321-8dfb-4c9a9c6900fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
