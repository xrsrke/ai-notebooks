{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14bf4fef-45ad-4da2-901f-70d33b728241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd0d6d-ef4b-477a-82d4-4f1fa4b10e78",
   "metadata": {},
   "source": [
    "### Create Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a6984-5005-4131-912a-13657b3ed606",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f057ad-2913-4d74-a9d6-bae1f8a8193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_height, latent_width = 64, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd59bc02-74cc-4c99-bda9-201d687271ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 1024, 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32a6eb0d-9d62-4eb8-8a57-45032faa6399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf9c7c57-51e4-431e-833d-f09d7b242ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2139a-3e8a-4c20-91b2-5eacc674c04a",
   "metadata": {},
   "source": [
    "A color image with size `width` and `height` after go through U-Net, it compressed to `latent_height`, `latent_width`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f795da6-4e7d-4589-8084-5be5cdc4659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_height, latent_width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905d15c-e5a4-4b1d-9f77-41b39b9afb2d",
   "metadata": {},
   "source": [
    "Create a pure noise use in forward diffusion process for 3 images. And explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df039ee5-2052-4ba5-a024-a8bdf7177a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afa72a0e-ae21-4eac-87de-dd47a571d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_color_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec4058da-9f02-4e07-b98a-53d32cc166ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(n_images, n_color_channels, latent_height, latent_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5ddab-47d5-458b-b698-8249626f0621",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "- `torch.randn()`: gaussian noise\n",
    "- `latent_height` and `latent_width`: When generate an image in forward diffusion process, we don't generate the image with target size (height, width) because it computation intensive, but we do in smaller size (latent_height, latent_width) and use VAEs to make it bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10f360dd-914c-4723-a8d0-09f2bbe9486c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3273ea5-b886-4e55-816c-5955a8cb6dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
