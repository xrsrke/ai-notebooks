{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515f5a06-0306-466b-8b27-db1d78c39332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36fc01d-20e8-4c38-b4e9-27b287da7dec",
   "metadata": {},
   "source": [
    "# `rearrange`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b7b64-b451-4bbe-8dfd-55f7d5b87bb6",
   "metadata": {},
   "source": [
    "### Composition of axes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df0f8a-7602-40a6-a731-a683d266a058",
   "metadata": {},
   "source": [
    "**Example 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aff2bd2-89e6-4eef-9c70-b62681e07b46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m70\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "images = torch.randn(5, 3, 64, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78fd436-6cd8-4352-9e30-efa6f84b0215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4631f7fc-d608-4365-b478-3ff59323f154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 64, 70])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f24b53-3849-43fc-a845-30cffa405aa9",
   "metadata": {},
   "source": [
    "`images` is a batch of `5` color images, each has height 64 and width 70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0886b4-3c84-42c5-9a5e-9a05a7a3f61d",
   "metadata": {},
   "source": [
    "Transpose the height and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83ba27ce-e6ac-4ae8-8384-3ad9c9caac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rearrange(\n",
    "    x,\n",
    "    'batch_size n_channels height width -> batch_size n_channels width height'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3786f74-4421-423e-81d4-74c3c032cb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 70, 64])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a245194-1b5e-4a33-b2f9-8aad3346e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rearrange(\n",
    "    x,\n",
    "    'batch_size n_channels height width -> batch_size (n_channels width) height'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28445654-900f-4e1a-8494-434fe763cbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 210, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35628ec8-f554-44e9-b9e7-f9e60d414d31",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c4ff1ee-62ea-414e-b07d-44c9430182c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(5, 3, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21a6c631-1e4a-41bf-96d4-5876aeff5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "307c672b-3730-4305-82b8-188a4e190e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 4, 4])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d48a79c-7e62-466c-b6b3-7acd571b82ed",
   "metadata": {},
   "source": [
    "`images` is a batch of `5` color images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa0ba5-aec6-4451-87a2-c479561e453b",
   "metadata": {},
   "source": [
    "Rearrange the dimensions of the `images` as bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8eb65b7b-ff81-4e32-a75f-e7fbaaa9d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rearrange(images, 'b c h w -> b c (h w)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db6ce5c3-ca7e-4c9a-aff1-f905f2d9096f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 16])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d2241c-6214-4cad-9e71-4c10791a18b4",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "acc2066d-5a35-4bf8-b38f-6b306af3e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(5, 3, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6f8d66c-0f7a-40b0-af3e-b2b649f2794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb742e32-ddb7-4a9e-9b84-501d7349a3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 4, 4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf1aaa-a370-4475-8b34-c85816860c53",
   "metadata": {},
   "source": [
    "`images` is a batch of `5` color images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd222d-165d-4fee-9f75-4179befd16e9",
   "metadata": {},
   "source": [
    "Flatten all images in `images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0e20ef0-e087-460f-ab39-cc969f131883",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rearrange(images, 'b c h w -> (b c h w)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a68289e-f55c-4c95-a8bd-22d6c630aaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080b7f02-fa37-4f9c-ba57-ef03de43c5fd",
   "metadata": {},
   "source": [
    "##### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bf2f8ea4-469c-4c04-8c26-bdeb5e8b920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(5, 3, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "de8f0273-9136-4c1f-b34e-681138eeb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "37e1250d-bd5c-4e11-bf34-4f053b4b2bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 4, 4])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87382b95-1f54-4e46-b8e1-20b0a3ca5065",
   "metadata": {},
   "source": [
    "`images` is a batch of `5` color images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07db5fd8-1246-4630-89b3-b042de2bd281",
   "metadata": {},
   "source": [
    "Flatten all images in `images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7556ebaf-67ff-4908-94d0-a78e9b05be9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rearrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrearrange\u001b[49m(images, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb c 1 h w -> b 1 c h 1 w\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rearrange' is not defined"
     ]
    }
   ],
   "source": [
    "#result = rearrange(images, 'b c 1 h w -> b 1 c h 1 w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e9426b18-0186-4861-89df-99cce62c982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e824bcb-9f04-4f00-bd0b-60affe3ec326",
   "metadata": {},
   "source": [
    "##### Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f815ed1-0d80-42e1-a294-daf80176f2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = torch.randn(5, 64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb0a8526-fba3-49be-9835-91702af00dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188a5d4-d3ab-45c7-a359-3bd94f4d1824",
   "metadata": {},
   "source": [
    "`images` is a batch of 5 black-while images, with the color channel in the last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67ffa093-42a0-42ef-b760-c95b2c27b2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 64, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf005d68-0f37-4699-acbe-dfd5043ada87",
   "metadata": {},
   "source": [
    "Rearrange the `images` without specifies the specific dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53e98447-198a-486f-af7c-5d2020a62335",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rearrange(images, '... 1 -> ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7be61340-ace8-4829-93dc-b9755ea35a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaedb80-a770-4ac1-a010-59d6239b1ead",
   "metadata": {},
   "source": [
    "### Decomposition of axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160d068-b153-4224-809c-b3dd81992394",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "67ed42ef-3487-4869-8056-b478d4aec75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(5, 3, 64*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d63dcf07-8985-4ec9-a904-dabca66e4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5959db2-3bd1-49d4-830c-86f899964a47",
   "metadata": {},
   "source": [
    "`images` is a batch of `5` color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "30e35d9c-5ecf-47d1-a671-5cb6574030bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 4096])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b477c652-8687-443d-bc74-edc39a067a91",
   "metadata": {},
   "source": [
    "Split the pixels in the third dimension as bellow, given `height` of each images is `64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "deef0d97-f963-4e89-a56c-0e28f2fb8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rearrange(images, 'b c (h w) -> b c h w', h=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5bbbda1d-8d6f-4e37-96de-e6b697db091c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 64, 64])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962544d-2ba9-486c-811c-1c263a9ed8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e750babe-731c-45ec-888f-60a459170fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d270e406-6158-4f4e-86af-8f3dfde8daea",
   "metadata": {},
   "source": [
    "# `reduce`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a344d85-0da0-4b41-8cb9-2f441a3d7a23",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "848a8059-caeb-498e-92c3-040d2a233e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(5, 3, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6499ee99-c944-401e-8a42-062ccff0382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b8231-4db7-4e85-b765-055e10abbf4b",
   "metadata": {},
   "source": [
    "`images` is a batch of `5` color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f69e76f6-1af0-4c1b-a975-98a498e573de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 4, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d79dbf-9889-4078-8388-79e2f7223cbc",
   "metadata": {},
   "source": [
    "Write an equivalent operation to `images.mean(dim=1)` using the `reduce` function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "671facb5-95dc-4430-8018-ef9245b0d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = reduce(images, 'b c h w -> b h w', reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92934485-aa1f-4de7-941e-cc3050625e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416da18d-aa71-4d74-878e-a14fe17cd2d4",
   "metadata": {},
   "source": [
    "### `repeat`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a256a54-b7c5-469f-9c59-70eb88163b0c",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f329d81-8334-4a88-b6f5-1acf76866fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(4).reshape(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54baff77-9e30-47ff-b36c-6cd94dc65968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c36b4ebf-21f6-4962-a337-178efb34c3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4743ea1e-5d9c-433e-9f07-74db98b13b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64773914-aaba-4b99-bc10-31c591d0edec",
   "metadata": {},
   "source": [
    "Given a tensor `x` with shape `(height, width)`, write the code to repeat the values along the `width` dimension using `repeat` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd912d6c-bcbe-4cef-9f84-dca5b433f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = repeat(x, 'h w -> h w new_axis', new_axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fa8f4f89-92e1-412f-9e9a-a07bb79ee25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5071978-f394-46ae-ae56-bc11c3bc8e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[2, 2],\n",
       "         [3, 3]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5def5-2c44-4de2-89af-f6af5983c801",
   "metadata": {},
   "source": [
    "# `Layers`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2189cfd-4538-442e-ae4b-3041f0efe174",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e30a6be7-e815-4cfb-80a9-68cc79877a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from einops.layers.torch import Rearrange, Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65228abf-f18c-4f90-8cc4-c15d32a8cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    Rearrange('h -> h')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d87e690-8dd8-4c0d-bee3-3a619ca6f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf094f7f-d4d3-4b4b-83ac-1e58a0eb23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4003935c-19e1-4514-81d4-39d5e8b12c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b98b89-b3a3-4c56-8785-40e6ace4f753",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `pack` and `unpack`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb3056-4b9b-4301-a27f-706ec4067da0",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32d3904-4d64-4d8f-9b8c-f1239c40be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95964cf6-91c0-4a2d-bbe5-d1d2ca8f3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = torch.randn(3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3644a8c2-a751-45eb-adc1-36b5aca82e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = torch.randn(3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "069f83a9-642c-4755-9d56-86847b8d2471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 64, 64]), torch.Size([3, 64, 64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1.shape, image2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "278523a0-4031-4520-8566-3eb101e402f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "EinopsError",
     "evalue": "Duplicates in axes names in pack(..., \"c h w -> c h w *\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stacked_images \u001b[38;5;241m=\u001b[39m \u001b[43mpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc h w -> c h w *\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/einops/packing.py:70\u001b[0m, in \u001b[0;36mpack\u001b[0;34m(tensors, pattern)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpack\u001b[39m(tensors: Sequence[Tensor], pattern: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, List[Shape]]:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    Packs several tensors into one.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    See einops tutorial for introduction into packing (and how it replaces stack and concatenation).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    Read the tutorial for introduction and application scenarios.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     n_axes_before, n_axes_after, min_axes \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# packing zero tensors is illegal\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     backend \u001b[38;5;241m=\u001b[39m get_backend(tensors[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/einops/packing.py:20\u001b[0m, in \u001b[0;36manalyze_pattern\u001b[0;34m(pattern, opname)\u001b[0m\n\u001b[1;32m     18\u001b[0m axes_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(axes)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axes_set):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuplicates in axes names in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(..., \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m axes_set:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo *-axis in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(..., \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mEinopsError\u001b[0m: Duplicates in axes names in pack(..., \"c h w -> c h w *\")"
     ]
    }
   ],
   "source": [
    "stacked_images = pack([image1, image2], 'c h w -> c h w *')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284de088-5913-45d2-8869-2e621980748b",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09db9b94-680c-47bd-93f3-e1391ed79f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rgb = torch.randn((64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ada7cfe7-9b32-4779-9127-f5fcded316c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_depth = torch.randn(64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8f8671a-6ecb-4836-8f95-d4664d748499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f821a6-5437-4f15-8284-8d39154411f1",
   "metadata": {},
   "source": [
    "`image_rgb` is a color image with color channel in the last dimension\n",
    "\n",
    "`image_depth` is just a black-white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62763002-7fb7-4b50-a549-6f5296304c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 64, 3]), torch.Size([64, 64]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_rgb.shape, image_depth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2668ff-47fd-4e36-b35f-1b9b93811823",
   "metadata": {},
   "source": [
    "Stack the `image_depth` to the color channel of `image_rgb` using `pack` + Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af4edb-9f93-4c7d-ad76-00664700efbd",
   "metadata": {},
   "source": [
    "**Hint**: The output of `pack` are `stacked_images`, and `ps`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195134f7-a808-402a-9700-455ceb60c434",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "\n",
    "In the pattern `h w *`,\n",
    "- The string `h w`: indicates that first two axes (`h` and `w`) are shared across all inputs, and also shared with output\n",
    "\n",
    "- The string `*`: indicates that the inputs will be stacked across the last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd1ed130-97f5-4f76-9d3c-d3f8a9260875",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_images, _ = pack([image_rgb, image_depth], 'h w *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "590f9e5a-e1e5-4484-8b59-fcc1ea779b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48412a6-3e0b-474c-9f31-7eb013a9eb6c",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937242c-4c8b-4f8a-b764-5e6c6558fc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68e7d592-a9b3-4810-856e-ae3c6426c1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c259d-8a6f-4ea6-933d-b5a8b51048d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack(stacked_images, ps, 'h w *')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
